{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QrEwnUgKKuqr"
   },
   "source": [
    " # Predict at Scale\n",
    "\n",
    "\n",
    "\n",
    " This script:\n",
    "\n",
    " - Loads the full processed Sentiment140 dataset\n",
    "\n",
    " - Randomly samples 100 tweets for prediction\n",
    "\n",
    " - Encodes these 100 examples in batches using the all-mpnet-base-v2 sentence transformer\n",
    "\n",
    " - Loads the final trained classifier model\n",
    "\n",
    " - Predicts probabilities for each example\n",
    "\n",
    " - Applies a threshold (0.5) to classify as 'sarcastic' or 'literal'\n",
    "\n",
    " - Shows class distribution and random sample of predictions\n",
    "\n",
    " - (Optionally) saves predictions to CSV\n",
    "\n",
    " - Uses the GPT API to classify each tweet in the sample\n",
    "\n",
    " - Compares model predictions to LLM labels and reports accuracy, TP, TN, FP, FN rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747115567383,
     "user": {
      "displayName": "Mohammad Soltanieh Ha",
      "userId": "12308918870841825745"
     },
     "user_tz": 240
    },
    "id": "LV2wXfuZKuqt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from keras.models import load_model\n",
    "import openai\n",
    "import json\n",
    "import time\n",
    "from google.colab import userdata # Import userdata to access secrets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1747115650587,
     "user": {
      "displayName": "Mohammad Soltanieh Ha",
      "userId": "12308918870841825745"
     },
     "user_tz": 240
    },
    "id": "C7kZ6iykKuqu"
   },
   "outputs": [],
   "source": [
    "# Load the full dataset\n",
    "full_df = pd.read_csv('processed_sentiment140.csv')\n",
    "\n",
    "# Select a random sample of 100 examples for prediction\n",
    "predict_df = full_df.sample(n=100, random_state=42).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458,
     "referenced_widgets": [
      "cf1a2e80a670450baed03c38fff3aa93",
      "8a23cbf60241403c866f3fadd7b48838",
      "d941fce36bd34b6585cea0641b987644",
      "2ebfa6813c7e45ebb64649fa122031b8",
      "427e2e6344cb46ce84f8a7ebbafd553a",
      "c6615ed3d12b49caa174a595361bda93",
      "0ea88adb1d1c47fb838bc6a994dac1d3",
      "de09c7acb541440d8cacb765abc331f5",
      "2c8f08e7fcc14eb9900012d960594c85",
      "49a98822c5794c338815ed8e99b1bb68",
      "3b507eb5fff7432bb4b10faede1fb63f",
      "2de7785d0c7f45e2b27290da279a54c1",
      "d6e78072bbfc4bff9fdf0e4d1e2db577",
      "403a12d564e34cde86fb4184c4f48615",
      "c4d0bb3c2b4547e18114afea061883a6",
      "2af337b0cc6345cd992304a69462b4a1",
      "80bf96529ed8409abf89f3b6ad0dd6ea",
      "d3b513b11ae74f5bb622cbdba10951a0",
      "c9cfa0fb35524274bba415ce23ab02b7",
      "629f6bbfa0a44465935f3038a3507eea",
      "52c41bf8f7ec4efbac89cd933d488683",
      "8b7206440bf9418eb48d488e66c655c1",
      "10cf0022670d40bc9f259f66a960faca",
      "1cafb7e3a3d64c9fbaf4877170bff44f",
      "4c977e3857c7472f82b81f0c1deacec9",
      "267583db41424af686f4073fb00522ea",
      "07e605607bd549e8bc1dcb84aa8d987e",
      "1318b6e8ba18426984b0c482e76c029c",
      "b8f06b51925348dbb9c9de8d675f67d2",
      "e0cc47147a1342b8adbc7ed680d54708",
      "7ec2e4ef07c64e7eb91b99f76b47f7dc",
      "20fca29ed99c4a569050268aa9fa9169",
      "b236e0381af74e12a48976ceda594700",
      "537df3eb9188466499012aeae92a7063",
      "9b368506d4cf42ce9f53900b3d07e89e",
      "865b507cdc9240c8978ff8d0012e1919",
      "0a4062cf801a46b2b812ed8f21cc0424",
      "d39a307052624c7b81573a180f11c6ed",
      "1788eeaf5a434cee88ab8b9461523a0f",
      "c6426b61a063405485d9ae42e4977434",
      "a099d18386404b2ab8fc117277ef3a5b",
      "fac671cbc59843a9a9261ce71f3131d7",
      "efd5b9f73d984c6198ee01619a7617c3",
      "c42be8added84fc6915ceca84457587b",
      "730186ab52044939a4f43229c0d6ba4a",
      "86fdca8777654b47b0253d48b8696d9f",
      "b89a3c8d354f419f9830869980f26001",
      "ef4eb669b83d4621a20f829899078dfa",
      "9e3fba342ac8438780a96e85a27a102a",
      "dfa9142f4fb64fb59be32ed7c56a8bea",
      "94cbd0a98ee4400fa53bb2adfc462a2d",
      "9c76f0663a044d9baea0bc58696d9e34",
      "0861df5007244c2eb184cd5e71a8ed3f",
      "51ba25ecdd944b0ca44fd22b19256d72",
      "d4d62361d83a4249a94009f726099253",
      "5508d9ef400c44ba947d1abf925a9f08",
      "bd25a0f20c7441d1abdd923d63576306",
      "422f596b6d11454ea7a02e01448bb36b",
      "3ce43288bc6d4f6d830a6e6ab914bb9f",
      "fd6fa5e5c9f44f64b0c8bc17c8cc4f4e",
      "885cd595bdee4525a84e21ae138f26a9",
      "ed3738cc605b40ae956a41050bc714be",
      "3b8f435db6824214a5ddd82696667145",
      "171b60a7471f48dfa50a655f6fedf5d1",
      "bf9fc8bf374c43198fd883e8e0b3d2e4",
      "011cf2162dbe4435853f4b4b87b51648",
      "cdbbc4114e8e4f539f93d8d690881662",
      "daa2942bc08142fa942134f3c1a534ec",
      "6946bdbc81b74b77b8219112f2ee4779",
      "02a251c597e848aa8dab15dd5c7992c2",
      "53a8283f114f4414a326f0400b99454d",
      "029cbb55647c493f917ee3108dcd67de",
      "f0733149e4b14d9f83af302c5e0d2582",
      "b17960be64c3476193eff29b861cf32b",
      "87ebaf6614bd42c5b230b59fbb530467",
      "e44cfea3751942728eedb4c63ace3ab2",
      "148545e1e2094d6aa17d5d2a8beb9df1",
      "1ed7a602577e45bb872ffbcdfaadbe70",
      "d5d280d5ec634a88b35491e28312101f",
      "3755aa9a4bb84417bb962610bb212c65",
      "bd4479d568004d2eb293d0758960fa99",
      "a202f999dda141d99adf9522f8528c16",
      "0619f3ba4a2a450b879d9015002f6525",
      "b362e53b30d14bd8a2b53bc154e79096",
      "22be26698e4049f7b9b431c9aa8f91bd",
      "0fa18279c89245ce8b6257dde9cc111d",
      "b7a6f97c265e437fade5b9c06aa53632",
      "19923ad507d040589cf50746fb1e0290",
      "5497e0029d32428083c405f536030a34",
      "505d9f5c26d04dd0820212df6746b220",
      "68a94da92dbd4e468fa32fa28ddcd0f8",
      "50f1806d0954427ea8b940666ebee940",
      "13edf7c692a24e89a682db97b24a9b95",
      "5c4240aa2ee845c0a7db285b8087d431",
      "ce27c0f8584a43309109fc925514fee2",
      "9db984c09fda4477944a173e6fb74331",
      "06fe39f1de4c4e2c87d8152e31eecc85",
      "808fdac113cc4cfe8b60b762235f656e",
      "a8949b17a3064cafbf48f777b213d172",
      "2ee43677bd7540a68749e26b40cb6388",
      "4637eae9c2f24cb0992321909855bc4f",
      "c944e8153b83433389050e8e5aa3a51b",
      "dad36234aa3348eb91f8289ca0575cc8",
      "c106fef5c32f4bf9a1296e83679c63f5",
      "6d43010221f4461893224dfed1335fcb",
      "3583609090194fc98ad74c024cb959e5",
      "8f4f5011914b4e15b21c81b992c3b747",
      "bb3379d69e974a569eddca4850b2a4d2",
      "bc05ced307884f07b3a7648d4d30d8cf",
      "6773d2cf3f9d403588b7a5a397139e5f",
      "6d06a4612506489f9c0817a230ad11b3",
      "ebb613970942439d9cba706fe3705d64",
      "88e9365610b74ef98ffde60a65524a16",
      "d1af9a50d7054035ac1ccb243164d786",
      "4c5e94514d9446e8aa1e2f2ee74a336a",
      "d0cd762fa3c44d0a9274a2d4a1918254",
      "4f0e3733f9d94164b43cd5252cbb6b4f",
      "d25843ef775c44358b1f3ad212d3c825",
      "3440ecef21334a9892843ae4105b34b8",
      "f304a6f3c324455ebd566bbbbdd16227",
      "ee7cf25cf7a3447faf3ab24f65861d8c"
     ]
    },
    "executionInfo": {
     "elapsed": 29975,
     "status": "ok",
     "timestamp": 1747115407699,
     "user": {
      "displayName": "Mohammad Soltanieh Ha",
      "userId": "12308918870841825745"
     },
     "user_tz": 240
    },
    "id": "3UnndYAuKuqv",
    "outputId": "f053743a-4639-4267-e8ab-913af3658c25"
   },
   "outputs": [],
   "source": [
    "# Load the same sentence transformer model used in training\n",
    "ST_model = SentenceTransformer('all-mpnet-base-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1747115655560,
     "user": {
      "displayName": "Mohammad Soltanieh Ha",
      "userId": "12308918870841825745"
     },
     "user_tz": 240
    },
    "id": "cHm079mcKuqv",
    "outputId": "aa7232e7-0e8c-4bad-c678-1df0d56d609d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding 100 examples in batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode the examples in batches\n",
    "batch_size = 32\n",
    "all_embeddings = []\n",
    "print('Encoding 100 examples in batches...')\n",
    "for i in tqdm(range(0, len(predict_df), batch_size)):\n",
    "    batch = predict_df['cleaned_text'].iloc[i:i+batch_size].tolist()\n",
    "    batch_embed = ST_model.encode(batch)\n",
    "    all_embeddings.extend(batch_embed)\n",
    "all_embeddings = np.array(all_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1747115656748,
     "user": {
      "displayName": "Mohammad Soltanieh Ha",
      "userId": "12308918870841825745"
     },
     "user_tz": 240
    },
    "id": "r0LARLa-Kuqv",
    "outputId": "17c2e1ee-a05f-4b48-a93d-662c6913a4c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load the final trained model\n",
    "final_model = load_model('final_classifier.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1747115657933,
     "user": {
      "displayName": "Mohammad Soltanieh Ha",
      "userId": "12308918870841825745"
     },
     "user_tz": 240
    },
    "id": "DkZ4eSAiKuqv",
    "outputId": "ab5624fd-8703-45d5-e593-60aca8b96f80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities\n",
    "probs = final_model.predict(all_embeddings)\n",
    "\n",
    "# Apply threshold to classify\n",
    "threshold = 0.5\n",
    "predict_df['predicted_probability'] = probs.flatten()\n",
    "predict_df['predicted_label'] = (probs.flatten() > threshold).astype(int)\n",
    "\n",
    "# Map back to string labels if needed (optional)\n",
    "label_map = {1: 'sarcastic', 0: 'literal'}\n",
    "predict_df['predicted_label_str'] = predict_df['predicted_label'].map(label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1747115659082,
     "user": {
      "displayName": "Mohammad Soltanieh Ha",
      "userId": "12308918870841825745"
     },
     "user_tz": 240
    },
    "id": "PJ1eegdMKuqw",
    "outputId": "c6720531-53d9-4567-9dfb-8345ee2c5b1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     text  \\\n",
      "725031  Was sending my last tweet typed in moon and it...   \n",
      "352959  In Tha House, Sore From Working Out...Kinda Mi...   \n",
      "601371  @Queluver55 just wanted to say hi and that her...   \n",
      "425948  TGIF but then its TGIS then oh man its Sunday....   \n",
      "567048  in time you will get it young grass hopper@nat...   \n",
      "\n",
      "        predicted_probability  predicted_label predicted_label_str  \n",
      "725031               0.431566                0             literal  \n",
      "352959               0.034415                0             literal  \n",
      "601371               0.001978                0             literal  \n",
      "425948               0.804007                1           sarcastic  \n",
      "567048               0.707501                1           sarcastic  \n",
      "\n",
      "Predicted class distribution:\n",
      "predicted_label_str\n",
      "literal      73\n",
      "sarcastic    27\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show a sample of predictions\n",
    "print(predict_df[['text', 'predicted_probability', 'predicted_label', 'predicted_label_str']].head())\n",
    "\n",
    "# Show statistics of predicted classes\n",
    "print(\"\\nPredicted class distribution:\")\n",
    "print(predict_df['predicted_label_str'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1747115660050,
     "user": {
      "displayName": "Mohammad Soltanieh Ha",
      "userId": "12308918870841825745"
     },
     "user_tz": 240
    },
    "id": "v_l7RHHBKuqw",
    "outputId": "dc4f034d-0669-4c43-eb97-dd25786ded14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions for 100 examples to predictions_100.csv\n"
     ]
    }
   ],
   "source": [
    "# Optionally, save predictions to a new CSV\n",
    "predict_df.to_csv('predictions_100.csv', index=False)\n",
    "print('Saved predictions for 100 examples to predictions_100.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 435,
     "status": "ok",
     "timestamp": 1747115661881,
     "user": {
      "displayName": "Mohammad Soltanieh Ha",
      "userId": "12308918870841825745"
     },
     "user_tz": 240
    },
    "id": "NmD0a50fKuqw"
   },
   "outputs": [],
   "source": [
    "# Load OpenAI API key from Colab secrets\n",
    "openai.api_key = userdata.get('OpenAI_API_Key')\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "def classify_with_llm(text, max_retries=3, wait_time=0.5):\n",
    "    prompt = (\n",
    "        \"Classify the following tweet as either 'literal' or 'sarcastic'. \"\n",
    "        \"Respond with only one word: literal or sarcastic.\\n\"\n",
    "        f\"Tweet: {text}\\nLabel:\"\n",
    "    )\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4.1-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant that classifies tweets as literal or sarcastic. Respond with only one word: literal or sarcastic.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0,\n",
    "                max_tokens=1\n",
    "            )\n",
    "            label = response.choices[0].message.content.strip().lower()\n",
    "            if 'lit' in label:\n",
    "                return 'literal'\n",
    "            elif 'sar' in label:\n",
    "                return 'sarcastic'\n",
    "            else:\n",
    "                return label\n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"Attempt {attempt + 1} failed: {str(e)}. Retrying in {wait_time} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "                wait_time *= 2\n",
    "            else:\n",
    "                print(f\"All {max_retries} attempts failed. Last error: {str(e)}\")\n",
    "                return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73351,
     "status": "ok",
     "timestamp": 1747115736199,
     "user": {
      "displayName": "Mohammad Soltanieh Ha",
      "userId": "12308918870841825745"
     },
     "user_tz": 240
    },
    "id": "OnmmEbCOKuqw",
    "outputId": "87b5fc6d-a842-4a6a-f605-8d30c7eb349d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying with LLM: 100%|██████████| 100/100 [00:46<00:00,  2.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# Apply LLM classification to the 100 samples (this will use tokens and take time)\n",
    "llm_labels = []\n",
    "for text in tqdm(predict_df['text'], desc='Classifying with LLM'):\n",
    "    llm_labels.append(classify_with_llm(text))\n",
    "predict_df['llm_label'] = llm_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1747115736202,
     "user": {
      "displayName": "Mohammad Soltanieh Ha",
      "userId": "12308918870841825745"
     },
     "user_tz": 240
    },
    "id": "Q-bMSdSzKuqw"
   },
   "outputs": [],
   "source": [
    "# Compare model predictions with LLM labels\n",
    "def get_tp_tn(row):\n",
    "    if row['predicted_label_str'] == 'sarcastic' and row['llm_label'] == 'sarcastic':\n",
    "        return 'TP'\n",
    "    elif row['predicted_label_str'] == 'literal' and row['llm_label'] == 'literal':\n",
    "        return 'TN'\n",
    "    elif row['predicted_label_str'] == 'sarcastic' and row['llm_label'] == 'literal':\n",
    "        return 'FP'\n",
    "    elif row['predicted_label_str'] == 'literal' and row['llm_label'] == 'sarcastic':\n",
    "        return 'FN'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "predict_df['llm_agreement'] = predict_df.apply(get_tp_tn, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1747115736212,
     "user": {
      "displayName": "Mohammad Soltanieh Ha",
      "userId": "12308918870841825745"
     },
     "user_tz": 240
    },
    "id": "UU_jv4ovKuqx",
    "outputId": "7832b432-3cda-4195-f9eb-929be0a059d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM agreement accuracy: 0.700\n",
      "TP: 16, TN: 54, FP: 11, FN: 19\n"
     ]
    }
   ],
   "source": [
    "# Report accuracy and confusion matrix\n",
    "accuracy = (predict_df['predicted_label_str'] == predict_df['llm_label']).mean()\n",
    "tp = (predict_df['llm_agreement'] == 'TP').sum()\n",
    "tn = (predict_df['llm_agreement'] == 'TN').sum()\n",
    "fp = (predict_df['llm_agreement'] == 'FP').sum()\n",
    "fn = (predict_df['llm_agreement'] == 'FN').sum()\n",
    "print(f'LLM agreement accuracy: {accuracy:.3f}')\n",
    "print(f'TP: {tp}, TN: {tn}, FP: {fp}, FN: {fn}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dAd0CT6FKuqx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "text_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
