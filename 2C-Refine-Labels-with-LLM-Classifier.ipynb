{"cells":[{"cell_type":"markdown","metadata":{"id":"8klGVmTHILIk"},"source":[" # Step 2C: Refine Labels with LLM Classifier\n","\n","\n","\n"," Validate naive model predictions using GPT-4.1-mini:\n","\n","\n","\n"," 1. Process: Load top 5000 high-confidence examples per class\n","\n"," 2. Classify: Use GPT-4.1-mini to reclassify each tweet (single-word response)\n","\n"," 3. Compare: Identify true/false positives/negatives between naive and LLM labels\n","\n"," 4. Save: Store results with agreement status (TP/TN/FP/FN) to 'data/llm_refined_labels.csv'\n","\n","\n","\n"," This step helps validate the quality of our naive classifier's predictions."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"OYFu-0SJILIn","executionInfo":{"status":"ok","timestamp":1747114348710,"user_tz":240,"elapsed":9226,"user":{"displayName":"Mohammad Soltanieh Ha","userId":"12308918870841825745"}}},"outputs":[],"source":["# Import necessary libraries\n","import os\n","import json\n","import pandas as pd\n","import openai\n","from tqdm import tqdm\n","import time\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"zTy_8uB-ILIo","executionInfo":{"status":"ok","timestamp":1747114357141,"user_tz":240,"elapsed":3476,"user":{"displayName":"Mohammad Soltanieh Ha","userId":"12308918870841825745"}}},"outputs":[],"source":["from google.colab import userdata # Import userdata to access secrets\n","\n","# Load OpenAI API key from Colab secrets\n","openai.api_key = userdata.get('OpenAI_API_Key')\n","\n","# Initialize OpenAI client\n","client = openai.OpenAI(api_key=openai.api_key)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"ySiN6ZlDILIo","executionInfo":{"status":"ok","timestamp":1747114390170,"user_tz":240,"elapsed":696,"user":{"displayName":"Mohammad Soltanieh Ha","userId":"12308918870841825745"}}},"outputs":[],"source":["# Load high-confidence predictions\n","high_conf = pd.read_csv('high_confidence_real_examples.csv')\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"jofMU8IpILIp","executionInfo":{"status":"ok","timestamp":1747114412798,"user_tz":240,"elapsed":89,"user":{"displayName":"Mohammad Soltanieh Ha","userId":"12308918870841825745"}}},"outputs":[],"source":["# Select top 5000 for each class by probability\n","literal_top = high_conf[high_conf['pred_label'] == 'literal'].nlargest(50, 'prob_0')\n","sarcastic_top = high_conf[high_conf['pred_label'] == 'sarcastic'].nlargest(50, 'prob_1')\n","top_examples = pd.concat([literal_top, sarcastic_top], ignore_index=True)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"aitAOuH1ILIp","executionInfo":{"status":"ok","timestamp":1747114414417,"user_tz":240,"elapsed":5,"user":{"displayName":"Mohammad Soltanieh Ha","userId":"12308918870841825745"}}},"outputs":[],"source":["# Function to classify with LLM (GPT-4.1-mini)\n","def classify_with_llm(text, max_retries=3, wait_time=0.5):\n","    prompt = (\n","        \"Classify the following tweet as either 'literal' or 'sarcastic'. \"\n","        \"Respond with only one word: literal or sarcastic.\\n\"\n","        f\"Tweet: {text}\\nLabel:\"\n","    )\n","    for attempt in range(max_retries):\n","        try:\n","            response = client.chat.completions.create(\n","                model=\"gpt-4.1-mini\",\n","                messages=[\n","                    {\"role\": \"system\", \"content\": \"You are a helpful assistant that classifies tweets as literal or sarcastic. Respond with only one word: literal or sarcastic.\"},\n","                    {\"role\": \"user\", \"content\": prompt}\n","                ],\n","                temperature=0,\n","                max_tokens=1\n","            )\n","            label = response.choices[0].message.content.strip().lower()\n","            # Enforce single-word response\n","            if 'lit' in label:\n","                return 'literal'\n","            elif 'sar' in label:\n","                return 'sarcastic'\n","            else:\n","                return label\n","        except Exception as e:\n","            if attempt < max_retries - 1:\n","                print(f\"Attempt {attempt + 1} failed: {str(e)}. Retrying in {wait_time} seconds...\")\n","                time.sleep(wait_time)\n","                wait_time *= 2\n","            else:\n","                print(f\"All {max_retries} attempts failed. Last error: {str(e)}\")\n","                return None\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nb3_OAmCILIp","executionInfo":{"status":"ok","timestamp":1747114467246,"user_tz":240,"elapsed":51506,"user":{"displayName":"Mohammad Soltanieh Ha","userId":"12308918870841825745"}},"outputId":"b359a6ff-d518-4459-bb5b-67176051925b"},"outputs":[{"output_type":"stream","name":"stderr","text":["Classifying with LLM: 100%|██████████| 100/100 [00:51<00:00,  1.94it/s]\n"]}],"source":["# Apply LLM classification (this may take a while and cost tokens)\n","llm_labels = []\n","for text in tqdm(top_examples['text'], desc='Classifying with LLM'):\n","    llm_labels.append(classify_with_llm(text))\n","top_examples['llm_label'] = llm_labels\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"u67rcr-NILIq","executionInfo":{"status":"ok","timestamp":1747114472482,"user_tz":240,"elapsed":3,"user":{"displayName":"Mohammad Soltanieh Ha","userId":"12308918870841825745"}}},"outputs":[],"source":["# Identify TP, TN, FP, FN, Other\n","def get_tp_tn(row):\n","    if row['pred_label'] == 'sarcastic' and row['llm_label'] == 'sarcastic':\n","        return 'TP'\n","    elif row['pred_label'] == 'literal' and row['llm_label'] == 'literal':\n","        return 'TN'\n","    elif row['pred_label'] == 'sarcastic' and row['llm_label'] == 'literal':\n","        return 'FP'\n","    elif row['pred_label'] == 'literal' and row['llm_label'] == 'sarcastic':\n","        return 'FN'\n","    else:\n","        return 'Other'\n","\n","top_examples['llm_agreement'] = top_examples.apply(get_tp_tn, axis=1)\n"]},{"cell_type":"markdown","source":["Uncomment the cell below to save the file"],"metadata":{"id":"0CW7aOihJDFz"}},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oavKU8CfILIq","executionInfo":{"status":"ok","timestamp":1747114475535,"user_tz":240,"elapsed":32,"user":{"displayName":"Mohammad Soltanieh Ha","userId":"12308918870841825745"}},"outputId":"cecdc58a-ff0b-4080-d27c-a1f8c0e70228"},"outputs":[{"output_type":"stream","name":"stdout","text":["All LLM-refined labels saved to llm_refined_labels.csv\n"]}],"source":["# Save all examples (not just TP/TN)\n","#output_path = 'llm_refined_labels.csv'\n","#top_examples.to_csv(output_path, index=False)\n","#print(f'All LLM-refined labels saved to {output_path}')\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5MEREFgvILIq","executionInfo":{"status":"ok","timestamp":1747114476492,"user_tz":240,"elapsed":22,"user":{"displayName":"Mohammad Soltanieh Ha","userId":"12308918870841825745"}},"outputId":"c98ab97b-3562-4ae5-e018-bcc94cf0804a"},"outputs":[{"output_type":"stream","name":"stdout","text":["True sarcastic: 45 (false sarcastic: 5)\n","True literal: 40 (false literal: 10)\n"]}],"source":["# Print summary: true/false sarcastic and literal\n","num_true_sarcastic = (top_examples['llm_agreement'] == 'TP').sum()\n","num_false_sarcastic = (top_examples['llm_agreement'] == 'FP').sum()\n","num_true_literal = (top_examples['llm_agreement'] == 'TN').sum()\n","num_false_literal = (top_examples['llm_agreement'] == 'FN').sum()\n","print(f\"True sarcastic: {num_true_sarcastic} (false sarcastic: {num_false_sarcastic})\")\n","print(f\"True literal: {num_true_literal} (false literal: {num_false_literal})\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IZVAGQPFILIq"},"outputs":[],"source":[]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":0}